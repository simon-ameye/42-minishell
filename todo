TODO

- refaire le getwords pour au il divise correctement a>b et cat a > > b
- poursuivre getfds
- historique
- C-c, C-v, C-\

- chevron perd siginfication into both s and d quotes
- dollar  perd signification into s quotes

____________________________________________
TESTS

cat | cat | ls
cat < Makefile > out | grep all
cd / | cd /

Warning ! ouble auotes from env expand should be kept, ex :
arg='"hello"'
<echo $arg> should return  <"hello">
I hope that : execve(ECHOPATH, {["arg"], [], []}) returns "hello"
<asxsax asx as sx| dkmsc | sx |> bugue !!

var='<'
echo $var file

cat < bar | echo "<" | cat <  | echo < bar
____________________________________________

digraph G
{

    a [label="GET_PROCESS_DATA :\ncreate PROCESS_DATA tab (nb of pipes + 1)\n"]
    b [label="LEXER (get_tokens): \nDetect words thx to spaces and quotes \n Do not removes quotes"]

    subgraph cluster_p
    {
        label = "PARSER\nIretates on process_data and on words";
        
        c [label="DOLLAR_EXPAND :\nreplace $text by value in env\nSet token IS_EXPENDED to avoid redirecting expended <\n"]
        d [label="GET_REDIRS : \nParse chevrons + files names\n Open all files, set FDs in tokens\n remove files names + chevrons"]
        dd [label="Remove quotes"]
        e [label="GET_FTYPE : \ndetect function (first word)\n set a number : 0 for execve, 1 for echo...\n"]
        f [label="GET_PATH : \ndetect function path\n only for 0 execve\n"]
    }
    g [label="CREATE_CHILDREN : \n fork(), set dup2() according to fds"]
    h [label="LAUNCH_PROCESSES (CHILDS) : \nWARNING ; ne pas forker si pas de pipe seulemen t pour les buildin\n close les fd"]
    i [label="ENDING : \n wait PIDS, free mem, return errors...\n close les fds"]

        process_data [label="PROCESS_DATA\n\
        string\n\
        tab of tokens\n\
        path (as requested by execve)\n\
        func_type\n\
        input stream\n\
        output stream\n\
        is_last\n\
        MORE USEFUL DATA"]
        
        tokens [label="TOKENS\n\
        Null terminated pointer tab\n\
        char    *word\l\
        int     *is_expanded\l\
        \n\
        "]

    a -> b -> c
    f -> g -> h ->i
    c -> d -> dd -> e -> f
    process_data -> tokens
}
____________________________________________
